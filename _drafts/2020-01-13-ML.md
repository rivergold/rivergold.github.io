# :fallen_leaf:Loss

## Cross-Entropy Loss

[PyTorch doc: CrossEntropyLoss](https://pytorch.org/docs/stable/nn.html#crossentropyloss)

[ML Glossary: Cross-Entropy](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy)

### Math

Binary classification

$$
-ylog(p) - (1-y)log(1-p)
$$

```python
def cross_entropy_loss(y_hat, y):
    if y == 1:
        return -log(y_hat)
    else:
        return -log(1 - y_hat)
```

Multiclass classification

$$
-\sum^{M}_{c=1}y_{c}log(p_{c})
$$

- $M$: number of classes
- $log$: natural log
- $y$: binary indicator (0 or 1), $y=1$ if class label $c$ is the correct classification for observation $o$
- $p$: predicted probability observation $o$ for class $c$
