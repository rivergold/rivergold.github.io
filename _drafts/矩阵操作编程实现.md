# Basics

Most operations has `variable.func` and `package.func`.

**Numpy**

- `np.func`
- `np.ndarray.func`

**PyTorch**

- `torch.func`
- `torch.Tensor.func`

Note: if example code use `package.func`, it means that there is no `variable.func` for this operation.

---

## View

### Numpy check is view or not

```python
a = np.array([[1, 2, 3], [4, 5, 6]])
# b is view of a
b = a.ravel()
print(b.base is a)
>>> True
print(np.may_share_memory(a, b))
>>> True
print(b.flags['OWNDATA'])
>>> False
```

**_Ref:_** [stackoverflow: How can I tell if NumPy creates a view or a copy?](https://stackoverflow.com/questions/11524664/how-can-i-tell-if-numpy-creates-a-view-or-a-copy)

---

## Broadcasting

Broadcasting only process when the operation is element-wise operation.

**:star2:The Broadcasting Rule:**

**In order to broadcast, the size of the trailing axes for both arrays in an operation must either be the same size or one of them must be one.**

**将参与计算操作的两个矩阵的 size 进行右对齐，对应位置的维度要么相等，要么其中一个为 1**

E.G.

```shell
Image	(3d array)	256 x	256 x	3
Scale	(1d array)	 	 	3
Result	(3d array)	256 x	256 x	3
```

```shell
A	(4d array)	8 x	1 x	6 x	1
B	(3d array)	 	7 x	1 x	5
Result	(4d array)	8 x	7 x	6 x	5
```

**_Ref:_** [Numpy doc: Array Broadcasting in Numpy](https://docs.scipy.org/doc/numpy/user/theory.broadcasting.html#array-broadcasting-in-numpy)

<!--  -->
<br>

---

<br>
<!--  -->

# Common Operations

## flatten

Convert $n \times w$ to 1-D vector.

**Numpy**

```python
x = np.array([[1, 2, 3], [4, 5, 6]])
y = x.flatten()
print(x)
>>> array([1, 2, 3, 4, 5, 6])
```

Note: result of `np.ravel()` is same as `np.flatten`, but `np.ravel`'s return is **view**, which means if you change `y`, will also change `x`.

**_Ref:_** [stackoverflow: What is the difference between flatten and ravel functions in numpy?](https://stackoverflow.com/a/28930580/4636081)

**PyTorch**

```python
x = torch.tensor([[1, 2, 3], [4, 5, 6]])
y = x.flatten()
>>> tensor([1, 2, 3, 4, 5, 6])
```

Note: `torch.Tensor.view(-1)` has the same effect with `np.ndarray.ravel()`.

---

## squeeze

Remove dimensions which size is 1.

**Numpy**

```python
x = np.random.randn(1, 2, 1)
print(x)
>>> array([[[ 0.        ],
            [-0.52306498]]])
# Note: y is view of x
y = x.squeeze()
print(y, y.shape)
>>> [ 0.         -0.52306498] (2,)
```

**PyTorch**

```python
x = torch.randn(1, 2, 1)
print(x)
>>> tensor([[[ 0.0000],
             [-0.7718]]])

# Note: y is view of x
y = x.squeeze(x)
print(y, y.size())
>>> tensor([ 0.0000, -0.7718]) torch.Size([2])
```

---

## unsqueeze

Insert new dimension before a axis.

**Numpy**

```python
x = np.array([1, 2, 3])
# Note: y is view of x
# Method 1
y = np.expand_dims(x, 0)
# Method 2
y = x[np.newaxis, ...]
print(y, y.shape)
>>> [[1 2 3]] (1, 3)
```

**PyTorch**

```python
x = torch.tensor([1, 2, 3])
y = x.unsqueeze(0)
print(y, y.size())
>>> tensor([[1, 2, 3]]) torch.Size([1, 3])
```
